{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>STATUS: Draft<i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from matplotlib.patches import Rectangle\n",
    "from IPython.display import Image\n",
    "import sys\n",
    "import HTM_Code as hc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last notebook, we built our first encoder. Admittedly, it was very simple. It just allows us to create integers and provide them to, and provide back indice location. It provided a little extra functionality so it could track previous, and comparison. And we established some rules that we would like to see in place. \n",
    "\n",
    "There are range of different encoders that we can use. Obviously more than just numbers. Let's build another simpler one now, called a Random Distributed Scalar Encoder\n",
    "\n",
    "At this point the amount of code in the notebook is getting a little busy, so we will start bringing it in. In the HTM_Code.py file in the same directory, I have all the functions we have created so far, and we have them here. Going forward, as we develop new functions and classes, we will keep them in this file (later we will need to think about distributing the contents in a more logical way).\n",
    "\n",
    "So far in our code we have 4 types of things: \n",
    "\n",
    "1. SDR Functions (creating SDRs, randomly flipping bits etc.)\n",
    "2. Metrics functions (compute union and overlap, olap set cardinality, comparing multiple over iterations)\n",
    "3. Visualisation functions (changing our arrays into matrices for visualisation\n",
    "4. Classes (1 so far, an encoder class)\n",
    "\n",
    "When I have created this, I have also cleaned up some functinos. I wanted teh visualisation to generalise to any shape\n",
    "\n",
    "We also need to start bing more careful of nomenclature which is subtle differently. I am gonig to stry and stick to BAMI, noting htm.core different \n",
    "\n",
    "https://numenta.com/assets/pdf/biological-and-machine-intelligence/BaMI-Encoders.pdf\n",
    "\n",
    "Its important to realise that the earlier things are sill much in play - so we need to consider noise, fault tolerance, and we will do this in the context the RDSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#99ddff; color:black; padding: 10px\">\n",
    "<b>Add to these notes:</b>\n",
    "\n",
    "I want to keep these notes in HTML so I don't have to host on a server, but a great exceriise is to use the ipython widgets to experience this like it happens in the video. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build another encoder now, and we can explain as we use it. THis will add a few more features, such as new overlap, it will be general encoder, that we can chain together....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- SUMMARY -------------------------\n",
      "Encode periodically:  False\n",
      "Values outside range will to be clipped:  True\n",
      "Bit Space Size:  400\n",
      "Number of bits to be used when encoding each value: 3\n",
      "Range of values that can be encoded: From  0  to  100\n",
      "Number of buckets available in bit space: 10586800\n",
      "Initial encoding:  [array([379, 341, 239])]\n",
      "Initial encoded value [0]\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## ADD IN how much overlap\n",
    "\n",
    "## add in resolution, periodicity\n",
    "\n",
    "class RandomDistributedScalarEncoder:\n",
    "    def __init__(self, bit_space_size = None,\n",
    "                number_of_bits_used_to_encode_value = None,\n",
    "                min_val = None,\n",
    "                max_val = None):\n",
    "        # Settings\n",
    "        self.bit_space_size = bit_space_size\n",
    "        self.number_of_bits_used_to_encode_value = number_of_bits_used_to_encode_value\n",
    "        self.clip_values_outside_range = True\n",
    "        self.is_periodic = False\n",
    "\n",
    "        self.resolution = 3\n",
    "        self.uniqueness = 1\n",
    "        self.min_value_to_encode = min_val\n",
    "        self.max_value_to_encode = max_val\n",
    "        self.max_bit_space_value = bit_space_size\n",
    "        self.min_bit_space_value = 0\n",
    "        \n",
    "        self.bucket_capacity = self.compute_bucket_capacity(self.bit_space_size, self.number_of_bits_used_to_encode_value)\n",
    "        \n",
    "        self.initial_encoding = np.array(hc.create_randomised_sdr(self.bit_space_size, self.number_of_bits_used_to_encode_value))\n",
    "                \n",
    "        self.encoded_values = []\n",
    "        self.encoded_values_bit_locations = []\n",
    "        self.encoded_values_and_bit_locations = {str(self.min_value_to_encode):self.initial_encoding}\n",
    "        self.encoded_values.append(self.min_value_to_encode)\n",
    "        self.encoded_values_bit_locations.append(np.array(self.initial_encoding))\n",
    "        \n",
    "        self.offset_for_array_indice = 1\n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_summary(self):\n",
    "        print(\"----------------- SUMMARY -------------------------\")\n",
    "        print(\"Encode periodically: \", self.is_periodic)\n",
    "        print(\"Values outside range will to be clipped: \",self.clip_values_outside_range)\n",
    "        print(\"Bit Space Size: \", self.bit_space_size)\n",
    "        print(\"Number of bits to be used when encoding each value:\", self.number_of_bits_used_to_encode_value)\n",
    "        print(\"Range of values that can be encoded: From \", self.min_value_to_encode, ' to ', self.max_value_to_encode)\n",
    "        print(\"Number of buckets available in bit space:\", self.bucket_capacity)\n",
    "        print(\"Initial encoding: \", self.encoded_values_bit_locations)\n",
    "        print(\"Initial encoded value\", self.encoded_values)\n",
    "        print(\"----------------------------------------------------\")\n",
    "\n",
    "\n",
    "    def compute_bucket_capacity(self, n, w):\n",
    "        return(sp.binomial(self.bit_space_size, self.number_of_bits_used_to_encode_value))\n",
    "\n",
    "    def compare_current_and_previously_encoded_value(self):\n",
    "        self.current_and_previous_encoded_values_comparison = np.abs(self.current_encoded_value / self.bit_space_size - self.previously_encoded_values[0] / self.bit_space_size)\n",
    "    \n",
    "    def create_buckets(self, iterations_needed):\n",
    "        \n",
    "        for i in range(0, iterations_needed):\n",
    "            random_bit_index_to_move = np.random.randint(0, self.number_of_bits_used_to_encode_value, 1)[0]\n",
    "            random_direction_to_move = np.random.randint(0, 2, 1)\n",
    "\n",
    "            next_sdr = self.encoded_values_bit_locations[-1].copy()\n",
    "            value = next_sdr[random_bit_index_to_move]\n",
    "            \n",
    "            if random_direction_to_move == 1:\n",
    "                value = next_sdr[random_bit_index_to_move] + 2\n",
    "            else: \n",
    "                value = next_sdr[random_bit_index_to_move] - 2\n",
    "                \n",
    "            if value > self.max_bit_space_value:\n",
    "                value = value - 3\n",
    "            elif value < 0:\n",
    "                value = value + 3\n",
    "\n",
    "            next_sdr[random_bit_index_to_move] = value\n",
    "\n",
    "            self.encoded_values_bit_locations.append(next_sdr.copy())\n",
    "            self.encoded_values.append(np.array(self.encoded_values[-1] + 1))\n",
    "            self.encoded_values_and_bit_locations[str(self.encoded_values[-1])] = next_sdr.copy()\n",
    "            \n",
    "            \n",
    "            \n",
    "    def add_value_to_buckets(value_choice):\n",
    "        pass\n",
    "\n",
    "    def encode_value_in_bit_space(self, value_choice):\n",
    "        \n",
    "        if (value_choice < self.encoded_values[-1]):\n",
    "            print(\"There is a bucket already created for the value\", value_choice, \": \", self.encoded_values_and_bit_locations[str(value_choice)])\n",
    "            return\n",
    "  \n",
    "        buckets_needed_to_encode_value = value_choice - len(self.encoded_values)\n",
    "        print(buckets_needed_to_encode_value , \"more buckets will be created to accomodate the value\", value_choice)\n",
    "        print(value_choice - self.encoded_values[-1])\n",
    "        self.create_buckets(buckets_needed_to_encode_value)\n",
    "        \n",
    "        #self.encoded_values.append(np.array(self.encoded_values[-1] + 1))\n",
    "        \n",
    "###################################################\n",
    "e1 = RandomDistributedScalarEncoder(bit_space_size = 400,\n",
    "                number_of_bits_used_to_encode_value = 3,\n",
    "                min_val = 0,\n",
    "                max_val = 100)\n",
    "\n",
    "e1.get_summary()\n",
    "# e1.encode_value_in_bit_space(5)\n",
    "# e1.encode_value_in_bit_space(7)\n",
    "# e1.encode_value_in_bit_space(3)\n",
    "# e1.encode_value_in_bit_space(17)\n",
    "# e1.encode_value_in_bit_space(4)\n",
    "\n",
    "\n",
    "\n",
    "# print(e1.encoded_values_bit_locations)\n",
    "# print(e1.encoded_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this encoder is quite a bit more sophisticated than our last one. We control a number of paramaters, we can set slipping, periodicity, it has much better capacity. We can control semantic similiarity to and extent and resolution. But what next, \n",
    "\n",
    "Date Time encoder, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/PTYlge2K1G8\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/PTYlge2K1G8\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But a date time encoder, is really just a multi encoder, we can encode multiple linear things that have different rates of change, and create semantic meaning. So let's create anotehr object that takes RSDE as objects: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiRandomDistributedScalarEncoder:\n",
    "    def __init__(self):\n",
    "        self.encoders = []\n",
    "        self.bit_space_size = None\n",
    "    def add_encoder(self, encoder):\n",
    "        self.encoders.append(encoder)\n",
    "    def join_encoders(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = MultiRandomDistributedScalarEncoder()\n",
    "\n",
    "e1 = RandomDistributedScalarEncoder(bit_space_size = 400,\n",
    "                number_of_bits_used_to_encode_value = 3,\n",
    "                min_val = 0,\n",
    "                max_val = 100)\n",
    "e2 = RandomDistributedScalarEncoder(bit_space_size = 400,\n",
    "                number_of_bits_used_to_encode_value = 3,\n",
    "                min_val = 0,\n",
    "                max_val = 100)\n",
    "e3 = RandomDistributedScalarEncoder(bit_space_size = 400,\n",
    "                number_of_bits_used_to_encode_value = 3,\n",
    "                min_val = 0,\n",
    "                max_val = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.add_encoder(e1)\n",
    "m1.add_encoder(e2)\n",
    "m1.add_encoder(e3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is a really powerful idea. We can think about multiple time series unfolding, date time components. Or we could think of symbolic music, track key changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2])"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1.encoded_values_and_bit_locations['3'] - e1.encoded_values_and_bit_locations['4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': array([115, 211, 205]),\n",
       " '1': array([117, 211, 205]),\n",
       " '2': array([115, 211, 205]),\n",
       " '3': array([115, 209, 205]),\n",
       " '4': array([115, 209, 203]),\n",
       " '5': array([115, 207, 203]),\n",
       " '6': array([115, 205, 203]),\n",
       " '7': array([115, 205, 205]),\n",
       " '8': array([113, 205, 205]),\n",
       " '9': array([113, 203, 205]),\n",
       " '10': array([115, 203, 205]),\n",
       " '11': array([113, 203, 205]),\n",
       " '12': array([113, 203, 207]),\n",
       " '13': array([111, 203, 207]),\n",
       " '14': array([109, 203, 207]),\n",
       " '15': array([107, 203, 207]),\n",
       " '16': array([107, 203, 205])}"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1.encoded_values_and_bit_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_union_and_overlap(SDR1_on_bits, SDR2_on_bits):\n",
    "    union = list(set(SDR1_on_bits).union(SDR2_on_bits))\n",
    "    overlap = list(set(SDR1_on_bits).intersection(SDR2_on_bits))\n",
    "    \n",
    "    return({\"union\": union, \"overlap\": overlap})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is starting to seem more like we saw in the early notebooks, we can how semantic similairty is affected by noise and subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is alot more we can do with encoders. Delta encoder, log encoder. A geospatial encoder particularly interesting, enconding values on a sphere, what other geometrical shapes, opens us up to diffent types of geometry adn topology also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at more encoders: \n",
    "https://numenta.com/assets/pdf/biological-and-machine-intelligence/BaMI-Encoders.pdf\n",
    "\n",
    "IMportant to capture semantics properly\n",
    "\n",
    "4 principles recall..... eg consider two numbers should be semantically similiar \n",
    "\n",
    "we need encoders to have to to incorporate noise and subsamplinig \n",
    "\n",
    "Encoding Daa for HTM systems - Purdy\n",
    "\n",
    "\n",
    "Date Time Encoder\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
