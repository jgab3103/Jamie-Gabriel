{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>STATUS: Draft<i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from matplotlib.patches import Rectangle\n",
    "from IPython.display import Image\n",
    "import HTM_Code as hc\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a pretty strong handle on SDRs and a number of measures from which to understand them. SDRs are a powerful data structure, that can take the the data we experience in teh world and put it into a standard format. Now its time, to go deeper, with encoders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/V3Yqtpytif0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/V3Yqtpytif0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Episode 5</h4>\n",
    "\n",
    "The idea of an encoder is really bound up with how related pieces of information gets put into the SDR format. The BAMI document provices four things that encoders that: \n",
    "\n",
    "1. An encoder can recieve semantically similar pices of data and tranform it into SDRs with overlapping active bits.\n",
    "\n",
    "2. The same input into an encoder should always produce the same SDR as output.\n",
    "\n",
    "3. The output should have the same dimensionality (total number of bits) for all inputs.\n",
    "\n",
    "4. The output should have similar sparsity for all inputs and have enough one-bits to handle noise and\n",
    "    subsampling.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For now, encoder is a function that allows passing of pieces of information that are correlated in some way. The phrase \"semantically similiar\" means the meaning is similiar captures the relationship, but  So for example, integers, passed into an encoder, relationships that are similiar in a domain are encoded, we are encoding the correlation \n",
    "\n",
    "Encoder is an object that assigns similiar SDRs by the domain similiarity. So in the domain of integers, 1 is closer to 2. In the domain of finite fields, say. \n",
    "\n",
    "To get a better sense of exactly what an encoder is, let's build one in Python. I will create the code first, and then we can walk through it to gain a better understanding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder:\n",
    "    def __init__(self, bit_space_size = None,\n",
    "                number_of_bits_used_to_encode_value = None,\n",
    "                min_val = None,\n",
    "                max_val = None,\n",
    "                is_randomly_distributed = None,\n",
    "                clip_values_outside_range = None):\n",
    "\n",
    "        self.bit_space_size = bit_space_size\n",
    "        self.number_of_bits_used_to_encode_value = number_of_bits_used_to_encode_value\n",
    "        self.clip_values_outside_range = clip_values_outside_range\n",
    "        self.is_periodic = False\n",
    "        self.is_randomly_distributed = is_randomly_distributed\n",
    "\n",
    "        self.resolution = 1\n",
    "        self.uniqueness = 1\n",
    "        self.min_value_to_encode = min_val\n",
    "        self.max_value_to_encode = max_val\n",
    "        self.max_bit_space_value = bit_space_size\n",
    "        self.min_bit_space_value = 0\n",
    "        self.encoded_values = []\n",
    "        self.encoded_values_bit_locations = []\n",
    "        self.offset_for_array_indice = 1\n",
    "        \n",
    "        self.bucket_capacity = self.compute_bucket_capacity(self.bit_space_size, self.number_of_bits_used_to_encode_value)\n",
    "        \n",
    "        if self.is_randomly_distributed:\n",
    "            self.initial_encoding = np.array(hc.create_randomised_sdr(self.bit_space_size, self.number_of_bits_used_to_encode_value))\n",
    "\n",
    "            self.encoded_values_and_bit_locations = {str(self.min_value_to_encode):self.initial_encoding}\n",
    "            self.encoded_values.append(self.min_value_to_encode)\n",
    "            self.encoded_values_bit_locations.append(np.array(self.initial_encoding))\n",
    "        \n",
    "    def get_summary(self):\n",
    "        print(\"----------------- SUMMARY -------------------------\")\n",
    "        print(\"|L3| Bit Space Size: \", self.bit_space_size)\n",
    "        print(\"|L4| Number of bits to be used when encoding each value:\", self.number_of_bits_used_to_encode_value)\n",
    "        print(\"|L5| Range of values that can be encoded: From \", self.min_value_to_encode, ' to ', self.max_value_to_encode)\n",
    "        print(\"|L6| Number of buckets available in bit space:\", float(self.bucket_capacity))\n",
    "        print(\"|L1| Encode periodically: \", self.is_periodic)\n",
    "        print(\"|L1| Values are encoded as are randomly distributed arrays: \", self.is_randomly_distributed)\n",
    "        print(\"|L1| Resolution: \", self.resolution)\n",
    "        print(\"|L1| Unique active bits per bucket: \", self.uniqueness)\n",
    "        print(\"|L2| Values outside range will to be clipped: \",self.clip_values_outside_range)\n",
    "        print(\"|L7| Encoded values bit locations:\\n \", self.encoded_values_bit_locations)\n",
    "        print(\"|L8| Encoded values\", self.encoded_values)\n",
    "        print(\"----------------------------------------------------\")\n",
    "\n",
    "        \n",
    "    def compute_bucket_capacity(self, n, w):\n",
    "        if self.is_randomly_distributed:\n",
    "            return(sp.binomial(self.bit_space_size, self.number_of_bits_used_to_encode_value))\n",
    "        else:\n",
    "            return(n - w + 1)\n",
    "\n",
    "    def create_buckets_for_randomly_encoded_values(self, iterations_needed):\n",
    "        \n",
    "        for i in range(0, iterations_needed):\n",
    "            random_bit_index_to_move = np.random.randint(0, self.number_of_bits_used_to_encode_value, 1)[0]\n",
    "            random_direction_to_move = np.random.randint(0, 2, 1)\n",
    "\n",
    "            next_sdr = self.encoded_values_bit_locations[-1].copy()\n",
    "            value = next_sdr[random_bit_index_to_move]\n",
    "            \n",
    "            if random_direction_to_move == 1:\n",
    "                value = next_sdr[random_bit_index_to_move] + 1\n",
    "            else: \n",
    "                value = next_sdr[random_bit_index_to_move] - 1\n",
    "                \n",
    "            if value > self.max_bit_space_value:\n",
    "                value = value - 2\n",
    "            elif value < 0:\n",
    "                value = value + 2\n",
    "\n",
    "            next_sdr[random_bit_index_to_move] = value\n",
    "\n",
    "            self.encoded_values_bit_locations.append(next_sdr.copy())\n",
    "            self.encoded_values.append(np.array(self.encoded_values[-1] + 1))\n",
    "            self.encoded_values_and_bit_locations[str(self.encoded_values[-1])] = next_sdr.copy()\n",
    "  \n",
    "\n",
    "    def encode_value_in_bit_space(self, value_choice):\n",
    "        print(\"\\nEncoding the value ->\", value_choice)\n",
    "        unclipped_value = value_choice\n",
    "        if self.clip_values_outside_range:\n",
    "            if value_choice < self.min_value_to_encode or value_choice > self.max_value_to_encode:\n",
    "                if value_choice < self.min_value_to_encode:\n",
    "                    value_choice = self.min_value_to_encode\n",
    "                else:\n",
    "                    value_choice = self.max_value_to_encode\n",
    "                print(\"The value of: \", unclipped_value, \"has been clipped to ->\", value_choice)\n",
    "            elif value_choice > self.min_value_to_encode or value_choice < self.max_value_to_encode:\n",
    "                pass\n",
    "        else:\n",
    "            print(\"Not a valid choice, \", value_choice, \" is outside encoder range\")\n",
    "            return\n",
    "\n",
    "        \n",
    "        if self.is_randomly_distributed:\n",
    "            if (value_choice < self.encoded_values[-1]):\n",
    "                print(\"There is a bucket already created for the value\", value_choice, \"-> \", self.encoded_values_and_bit_locations[str(value_choice)])\n",
    "                if unclipped_value < self.min_value_to_encode or unclipped_value > self.max_value_to_encode:\n",
    "                    print(\"This bucket will be used to encode\", unclipped_value)\n",
    "                    self.encoded_values_and_bit_locations[str(unclipped_value)] = self.encoded_values_and_bit_locations[str(value_choice)]\n",
    "                return\n",
    "            \n",
    "            buckets_needed_to_encode_value = value_choice - self.encoded_values[-1]\n",
    "            print(\"Current number of buckets: \" , len(self.encoded_values))\n",
    "            print(\"Value held in first bucket: \", self.min_value_to_encode)\n",
    "            print(\"Number of additional buckets required to accomodate the value choice of\", value_choice, \": \", buckets_needed_to_encode_value)\n",
    "            self.create_buckets_for_randomly_encoded_values(buckets_needed_to_encode_value)\n",
    "            self.encoded_values_and_bit_locations[str(unclipped_value)] = self.encoded_values_and_bit_locations[str(value_choice)]\n",
    "        \n",
    "        else:\n",
    "            window = [value_choice, value_choice + self.number_of_bits_used_to_encode_value]\n",
    "            all_values = np.arange(window[0], window[1])\n",
    "            self.encoded_values_bit_locations.append(all_values)\n",
    "            self.encoded_values.append(value_choice)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are quite few functions here, and some of them are for future encoders we might want to build, so we will just take it simply. \n",
    "\n",
    "The first thing to is initialise an encoder and pass it some values, and get a summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- SUMMARY -------------------------\n",
      "|L3| Bit Space Size:  64\n",
      "|L4| Number of bits to be used when encoding each value: 8\n",
      "|L5| Range of values that can be encoded: From  0  to  56\n",
      "|L6| Number of buckets available in bit space: 57.0\n",
      "|L1| Encode periodically:  False\n",
      "|L1| Values are encoded as are randomly distributed arrays:  False\n",
      "|L1| Resolution:  1\n",
      "|L1| Unique active bits per bucket:  1\n",
      "|L2| Values outside range will to be clipped:  True\n",
      "|L7| Encoded values bit locations:\n",
      "  []\n",
      "|L8| Encoded values []\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "bit_space_size_choice = 64\n",
    "number_of_bits_used_to_encode_value_choice = 8\n",
    "\n",
    "e1 = Encoder(bit_space_size = bit_space_size_choice,\n",
    "                number_of_bits_used_to_encode_value = number_of_bits_used_to_encode_value_choice,\n",
    "                min_val = 0,\n",
    "                max_val = 56,\n",
    "            is_randomly_distributed = False,\n",
    "            clip_values_outside_range = True)\n",
    "e1.get_summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what is this encoder telling us? Our encoder will encode values of  note that, for now at least, we are not worried about efficienty, but simplicity. let's create an instance of it with some initial parameters and see what it can do:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our encoder tells us it has some initial set up. The whole bit space appears to be 64, and any value that I would want to encode in this space will be 5 bits in length. If you think of this as an array with length 64, I can put 50 buckets (the first starting at index 1 of the array, the second starting at index two) into that space and its possible to encode 60 unique values. \n",
    "\n",
    "My initital settings however say that the range to from -10 to 100. So this will let me put any scalar, starting from -10 onwards, until I run out of buckets. After that, for any number I try and encode to the top of my range, it will just encode it to the very last bucket. We We can get around this by setting the encoder to periodic, which will do so later, or by just scaling back the range so the buckets can accomodate it. \n",
    "\n",
    "Note that the number of 50 buckets assumes that I have 1 unique bits per encoded value. So, for example, the value 8 and 9 starts at array indice 8 and 9 respectively, and 8 has 1 unique bit and the rest shared with adjacenct values. \n",
    "\n",
    "So now let's put some values into my encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Encoding the value -> 5\n",
      "\n",
      "\n",
      "Encoding the value -> 99\n",
      "The value of:  99 has been clipped to -> 56\n",
      "\n",
      "\n",
      "Encoding the value -> 33\n",
      "\n",
      "\n",
      "Encoding the value -> 34\n",
      "----------------- SUMMARY -------------------------\n",
      "|L3| Bit Space Size:  64\n",
      "|L4| Number of bits to be used when encoding each value: 8\n",
      "|L5| Range of values that can be encoded: From  0  to  56\n",
      "|L6| Number of buckets available in bit space: 57.0\n",
      "|L1| Encode periodically:  False\n",
      "|L1| Values are encoded as are randomly distributed arrays:  False\n",
      "|L1| Resolution:  1\n",
      "|L1| Unique active bits per bucket:  1\n",
      "|L2| Values outside range will to be clipped:  True\n",
      "|L7| Encoded values bit locations:\n",
      "  [array([ 5,  6,  7,  8,  9, 10, 11, 12]), array([56, 57, 58, 59, 60, 61, 62, 63]), array([33, 34, 35, 36, 37, 38, 39, 40]), array([34, 35, 36, 37, 38, 39, 40, 41])]\n",
      "|L8| Encoded values [5, 56, 33, 34]\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "e1.encode_value_in_bit_space(value_choice=5)\n",
    "e1.encode_value_in_bit_space(value_choice=99)\n",
    "e1.encode_value_in_bit_space(value_choice=33)\n",
    "e1.encode_value_in_bit_space(value_choice=34)\n",
    "e1.get_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have encoded in order, 34, 33, 5 and 99. This leaves me a current encoded value of 13, and a bunch of previous values I have encoded. My encoder is holding onto these so we can to comparisons. \n",
    "\n",
    "Let's visualise this using the visualization functions we have already created: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, figsize=(16, 3))\n",
    "\n",
    "ax1 = hc.create_axis_for_sdr(ax1, np.sqrt(bit_space_size_choice) + 1, np.sqrt(bit_space_size_choice) + 1, number_of_bits_used_to_encode_value_choice, \"34\")\n",
    "ax2 = hc.create_axis_for_sdr(ax2, np.sqrt(bit_space_size_choice) + 1, np.sqrt(bit_space_size_choice) + 1, number_of_bits_used_to_encode_value_choice, \"33\")\n",
    "ax3 = hc.create_axis_for_sdr(ax3, np.sqrt(bit_space_size_choice) + 1, np.sqrt(bit_space_size_choice) + 1, number_of_bits_used_to_encode_value_choice, \"34 and 33\")\n",
    "ax4 = hc.create_axis_for_sdr(ax4, np.sqrt(bit_space_size_choice) + 1, np.sqrt(bit_space_size_choice) + 1, number_of_bits_used_to_encode_value_choice, \"33 and 5\")\n",
    "ax5 = hc.create_axis_for_sdr(ax5, np.sqrt(bit_space_size_choice) + 1, np.sqrt(bit_space_size_choice) + 1, number_of_bits_used_to_encode_value_choice, \"99 (clipped)\")\n",
    "\n",
    "coords1 = hc.convert_sdr_to_tuple_for_visualisation(e1.encoded_values_bit_locations[-1], bit_space_size_choice)\n",
    "coords2 = hc.convert_sdr_to_tuple_for_visualisation(e1.encoded_values_bit_locations[-2], bit_space_size_choice)\n",
    "coords3 = hc.convert_sdr_to_tuple_for_visualisation(e1.encoded_values_bit_locations[0], bit_space_size_choice)\n",
    "\n",
    "union_and_overlap = hc.compute_union_and_overlap(e1.encoded_values_bit_locations[-1], e1.encoded_values_bit_locations[-2])\n",
    "\n",
    "coords4 = hc.convert_sdr_to_tuple_for_visualisation(union_and_overlap['union'], bit_space_size_choice)\n",
    "coords5 = hc.convert_sdr_to_tuple_for_visualisation(union_and_overlap['overlap'], bit_space_size_choice)\n",
    "\n",
    "coords6 = hc.convert_sdr_to_tuple_for_visualisation(e1.encoded_values_bit_locations[1], bit_space_size_choice)\n",
    "\n",
    "\n",
    "SDR1 = [ax1.add_patch(Rectangle(coords1[i], 1, 1, color=\"blue\")) for i in range(len(coords1))]\n",
    "SDR2 = [ax2.add_patch(Rectangle(coords2[i], 1, 1, color=\"blue\")) for i in range(len(coords2))]\n",
    "SDR3 = [ax3.add_patch(Rectangle(coords4[i], 1, 1, color=\"orange\")) for i in range(len(coords4))]\n",
    "SDR3 = [ax3.add_patch(Rectangle(coords5[i], 1, 1, color=\"blue\")) for i in range(len(coords5))]\n",
    "SDR4 = [ax4.add_patch(Rectangle(coords1[i], 1, 1, color=\"orange\")) for i in range(len(coords1))]\n",
    "SDR4 = [ax4.add_patch(Rectangle(coords3[i], 1, 1, color=\"blue\")) for i in range(len(coords3))]\n",
    "SDR5 = [ax5.add_patch(Rectangle(coords6[i], 1, 1, color=\"blue\")) for i in range(len(coords6))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#99ddff; color:black; padding: 10px\">\n",
    "<b>Add to these notes:</b>\n",
    "\n",
    "I want to keep these notes in HTML so I don't have to host on a server, but a great exceriise is to use the ipython widgets to experience this like it happens in the video. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 5 visualisations here: 41, 42, the overlap between then similiar and we can see this by looking at comparison. Ten for any value that is in our range but not buckets, we will just the max back, so the value 99. \n",
    "\n",
    "Note there is an underlying idea here of semantic similiarity. How different is 41 and 5. the simplest metric. This gives us a value between 0 and 1 that tells us about thier similiarity. We will get to that soon, but first, let's do another one, this time random: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_space_size_choice = 64\n",
    "number_of_bits_used_to_encode_value_choice = 8\n",
    "\n",
    "e2 = Encoder(bit_space_size = bit_space_size_choice,\n",
    "                number_of_bits_used_to_encode_value = number_of_bits_used_to_encode_value_choice,\n",
    "                min_val = 0,\n",
    "                max_val =300,\n",
    "            is_randomly_distributed = True,\n",
    "            clip_values_outside_range = True)\n",
    "e2.get_summary()\n",
    "\n",
    "\n",
    "# e2.encode_value_in_bit_space(value_choice=1)\n",
    "# e2.encode_value_in_bit_space(value_choice=9)\n",
    "# e2.encode_value_in_bit_space(value_choice=-10)\n",
    "# e2.encode_value_in_bit_space(value_choice=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this encoder has some different settings. The main difference I have set <code>is_randomly_distributed</code> to True. This means that each value is a randomly distributed array. When I set the encoder like this, it creates the randomly distrubted array for the minimum value in the range. Let's visualise it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(1, 1, figsize=(4, 4))\n",
    "\n",
    "ax1 = hc.create_axis_for_sdr(ax1, np.sqrt(bit_space_size_choice) + 1, np.sqrt(bit_space_size_choice) + 1, number_of_bits_used_to_encode_value_choice, \"-10\")\n",
    "\n",
    "coords1 = hc.convert_sdr_to_tuple_for_visualisation(e2.encoded_values_bit_locations[-1], bit_space_size_choice)\n",
    "\n",
    "SDR1 = [ax1.add_patch(Rectangle(coords1[i], 1, 1, color=\"blue\")) for i in range(len(coords1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note it still needs to be semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2.encode_value_in_bit_space(value_choice=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2.encode_value_in_bit_space(value_choice= 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now there are 7 buckets that have been created: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2.encode_value_in_bit_space(value_choice= -10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2.encoded_values_and_bit_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(16, 3))\n",
    "\n",
    "ax1 = hc.create_axis_for_sdr(ax1, np.sqrt(bit_space_size_choice) + 1, np.sqrt(bit_space_size_choice) + 1, number_of_bits_used_to_encode_value_choice, \"0\")\n",
    "ax2 = hc.create_axis_for_sdr(ax2, np.sqrt(bit_space_size_choice) + 1, np.sqrt(bit_space_size_choice) + 1, number_of_bits_used_to_encode_value_choice, \"1\")\n",
    "ax3 = hc.create_axis_for_sdr(ax3, np.sqrt(bit_space_size_choice) + 1, np.sqrt(bit_space_size_choice) + 1, number_of_bits_used_to_encode_value_choice, \"6\")\n",
    "ax4 = hc.create_axis_for_sdr(ax4, np.sqrt(bit_space_size_choice) + 1, np.sqrt(bit_space_size_choice) + 1, number_of_bits_used_to_encode_value_choice, \"-9\")\n",
    "\n",
    "coords1 = hc.convert_sdr_to_tuple_for_visualisation(e2.encoded_values_and_bit_locations[\"0\"], bit_space_size_choice)\n",
    "coords2 = hc.convert_sdr_to_tuple_for_visualisation(e2.encoded_values_and_bit_locations[\"1\"], bit_space_size_choice)\n",
    "coords3 = hc.convert_sdr_to_tuple_for_visualisation(e2.encoded_values_and_bit_locations[\"6\"], bit_space_size_choice)\n",
    "coords4 = hc.convert_sdr_to_tuple_for_visualisation(e2.encoded_values_and_bit_locations[\"-10\"], bit_space_size_choice)\n",
    "\n",
    "p1 = [ax1.add_patch(Rectangle(coords1[i], 1, 1, color=\"blue\")) for i in range(len(coords1))]\n",
    "p2 = [ax2.add_patch(Rectangle(coords2[i], 1, 1, color=\"blue\")) for i in range(len(coords2))]\n",
    "p3 = [ax3.add_patch(Rectangle(coords3[i], 1, 1, color=\"blue\")) for i in range(len(coords3))]\n",
    "p4 = [ax4.add_patch(Rectangle(coords4[i], 1, 1, color=\"blue\")) for i in range(len(coords4))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is quite powerful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So se can say that closer to zero the more similiar. This is not great, but it is just a linear score. In fact this encoder has lots of limiations, but it is a start. \n",
    "\n",
    "Before we go on to other types of encoders, let's spend some more time on the semantic similiarity measures, and formalise the rules we use a bit: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These rules suppose we have some be an an arbitrary input space, $A$. In the space  $S(n, k)$ is a set of SDRs that each have the length n and each have k on bits. We are interested in encoding the semantic similiarity of any of the SDRs in this set, and we will call our semantic similarity measure $d_a$, a function that can be appled to a number of SDRs in a given input space.  \n",
    "\n",
    "We define that our distance function needs to be able to fulfill 3 properties. Note also that, I am a not a big fan of using the word distance, and will probably swap this out, but for now it works well.\n",
    "\n",
    "First rule our distnance function needs to satisfy: \n",
    "\n",
    "$$\\forall x, y \\in A, d_A(x, y) \\ge 0 $$\n",
    "\n",
    "This says, for any  in 2 SDRs in the set (here denoted as $x$ and $y$, the disntance function must return a value greater than or equal to zero. Proximity function\n",
    "\n",
    "Second rule our distnance function needs to satisfy: \n",
    "\n",
    "$$\\forall x, y \\in A, d_A(x, y) \\equiv d_A(x, y) $$\n",
    "\n",
    "This says that our distance function must return the same output regardless, of the order we call our SDR in. So in teh example above, if we compute distance between 5 and 41, it is the same as computing distance for 41 and 5. \n",
    "\n",
    "Third rule our distnance function needs to satisfy: \n",
    "\n",
    "$$\\forall x, y \\in A, d_A(x, x) = 0 $$\n",
    "\n",
    "This says that the distance from the SDR to itself must be the the same. So we are getting to the point where we can compare distnance and metric scores, and overlap. Let's make it a little more reigou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define 1 more rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we or union and overlap function could do with some work.Let's define a evaluation metric for an encoder\n",
    "\n",
    "1. Let $O(s,t)$ be number of overlapping bits\n",
    "\n",
    "For encoder $f: A \\rightarrow S(n,k) $ and $\\forall w, x, y,z \\in A$:\n",
    "\n",
    "$$O(f(w), f(x)) \\ge O(f(y), f(z)) \\equiv d_A(w, x) \\le d_A (y, z)$$\n",
    "\n",
    "So this tells that the overap score for 2 SDRs, $w$ and $x$ is greater than the overlap score for $y$ and $z$, the disance between $w$ and $x$ will be less than distance $y$ and $z$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can desing metrics however we want, as long as they define these rules"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
