{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>STATUS: Draft<i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From numenta.org: \n",
    "\n",
    "<i>\"Hierarchical Temporal Memory is a foundational technology for the future of machine intelligence based upon the biology of the neocortex\"</i>\n",
    "\n",
    "IN these notebooks I will explore how to use HTM to create machine intelligence. There is quite a bit to do \n",
    "\n",
    "As a first step, I would advise you to get aquainted with details at numenta.org, and join the HTM forum. For a while, many of the questions won't make a lot of sense and that is ok. What we are seeing is a cross roads between issues in neuroscience, programming and computer science, and machine learning. It is cross displinary in the sense that it can draw deeply from computer science, and medical neurosicnce and makes assumptions that you can keep up. So we will start in a gentle way and build up concepts. \n",
    "\n",
    "There are lots of machine learning, the purpose of these notebooks is to explroe HTM, a different approach, and provide both workign the code and the theory. It can seem a little difficult at times. \n",
    "\n",
    "\n",
    "I am going draw heavily on a few key resources, and you might to deal with them directly also. To get going, I am going to go over Matt Taylor's lectures on HTM school found here. This will bring us fact to face with a number of issues that touch other fields such as Boolean Algebra, and Information Theory, and Medical Neoroscience. I will cite things carefully, and also take the opportunity (integrate a definion of entropy into what we are doing, locate Shannon's work, and provide a simipliefed overview. Once we have the basics in place I will move toward key papers in teh field. I will develope a accomanying literature review as we go forward\n",
    "\n",
    "The goal in these notebooks will be to move us to working with a workign with with HTM and be able to apply it in new domains, understand the code base, and understand the related with a deep understanding. In many ways, the study of HTM is a discipline in its own right, it has its own nomenclature, and we need to develop this and understand this if we want to work effectively. \n",
    "\n",
    "\n",
    "\n",
    "#### Getting things set up: \n",
    "\n",
    "Exploring HTM code will is often hampered by the difficulty in setting things up. Trying to isntall through the Python implmentation you can set up, its difficult on Windows, it's sometimes messy on Linux and Mac. So before we do anything else, let's set things up and head to the code being in a hello-world state before we do antying else. Note that to do this, you will need Administrative rights to install software on your computer (becasue of isntalling Docker) After that, we will be able to explroe the code in teh context of an extisting code and work with examples. \n",
    "\n",
    "By way of context, Numenta has open sourced both its original code base and its underlying documetnation. Because of this, there are a number of community implementation of the codes, all of which have varying degrees of maturity. The one we will install is the most standardised and the most popular, htm.core which can be found on gitbub here. \n",
    "\n",
    "The htm.core code base was written C++ and also has a python bindings version. To get things started, and move to our hello-world, we are doing to install the C++ version. For many getting started, I imagine you would want to use Python. The reason we are not going to do this is that it's far simpler to install the C++ version as you run into machine specific issues, that are not hard to resolve, but can seem a little cryptic if you haven't done this before. Also, the C++ code, even if you have only used python, is quite easy to read. I will also provide some resources to go further with it. It will also get us acquainted with the some of the core technologies to build C++ projects and provide a solid foundation if you want to build production ready HTM projects in the future. \n",
    "\n",
    "I will take through a line by line set up of the code on C++ and let's end by running an example. Then we can get to back to understanding the theory. Assuming you have nothing installed, this will take about 10 minutes. \n",
    "\n",
    "\n",
    "The steps we are doing to undertake to install the htm.core code are: \n",
    "\n",
    "1. Download the Atom IDE and Docker, and create an account\n",
    "2. Use Docker Ubuntu create a Linux Ubuntu Container\n",
    "3. Create a folder on our machine that the Lunix Ubuntu Container can see and go into the Container command line\n",
    "4. Download the htm.core code and put it into the folder that our Docker Container can see\n",
    "5. Go into the Docker Container command line and issue some commands to install our code as executables. \n",
    "6. Run the \"hello\" and \"mnist\" examples to check to check everything works as expected \n",
    "7. Make a tiny change in the htm.core code to demonstrate that we can recompile the code. \n",
    "\n",
    "Assuming you have nothing set up, this will take a bout 5-10 minutes\n",
    " \n",
    " We will get this out of the way now, and then we will spend a good deal of time focusing on theory itself\n",
    " \n",
    "<h4>Step 1: Download the Atom IDE and Docker, and create a Docker account </h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "htm - unique approach\n",
    "\n",
    "build systems on same principles...\n",
    "\n",
    "neocortex - 75% of brain  / evolved in mammals\n",
    "in humans, size of 2.5mm thick, scrunhed up inside the skull\n",
    "\n",
    "older parts - eatings/sleeping/sex\n",
    "\n",
    "neocortex - memories/identity/intelligence - \"Seat of intelligence\"\n",
    "\n",
    "slices under microscrope - cellular structure almost identical, visual / auditory all the same, tells us that problems brains solve, solve in same way, same cortical structure, same algorithmic structure\n",
    "\n",
    "Neocotex regions - nerve fbers, through white matter - lower levels  come up through higher levels, output, sent upward\n",
    "\n",
    "As we climb /ascend, ideas become more abstract and more permnanent\n",
    "\n",
    "lower levels - edges / borders\n",
    "higher levels - shape recognicition\n",
    "higher - object recognision\n",
    "higher - ideas and memories\n",
    "\n",
    "HTM - theory - common processes , not concerned all diff ways info come in, concertned with processing when info arises \n",
    "\n",
    "We can can focus on region - as they are all the same, we can create arbitrary complexity\n",
    "\n",
    "human - 20-30 billion neorons, state is what is on, and we find remarkably small percentate of bits are on - this is the \"State\" gnerally about 2% on at any given time\n",
    "\n",
    "\n",
    "\"Sparse Distributed Represntentaiotn\" SDR key element, whehter on or off - can be rep as array as 1s and 0s whether it is active or not...taken from neuroscience - SDR - region and whether they are on or off....\n",
    "\n",
    "You need SDR as basic data strduure\n",
    "\n",
    "\n",
    "2 basic inputs into neocortex - 1 - motor commands copy gonig out of old brain and being sent to control muscles, coming in, copy goes into neocortex, so it can undertand how it interacting\n",
    "2 - sensory input, coming from all the, touch, smell etc. all copied and sent to neocortex - represetnation of what is happening in the world - provide sensory motor model, what is happening, and how it is interacting....eg optic nerve, sending new different pictures, provides continuity, data comes from our brains to provide this also\n",
    "\n",
    "HTM systems need sensory organse - sensory encoders - takes data type, converts into SDR, need to turn data type into SDR - all take some kind of data, converts them into SDR that system can understand. \n",
    "\n",
    "We can create encoders that have no biological counterpart - eg geocoding encoder. We can see its anomalies etd\n",
    "\n",
    "At heart of the theory is an aglorithm called temporal memory - learns patterns that are changing over time. Operates on motor commands and sens imput - temporal memory biggest different to standard ML. HTM starts with assumption tha teverything based on memory and recall of sequences of patterns. \n",
    "\n",
    "HTM systems learn continuous - no training set, no batch, model changes as data changes\n",
    "\n",
    "HTM build predictive model of the world, and adapt to how well it i going \n",
    "\n",
    "People working on neural networks over 50 years ago, sicne then things advanced, better understnadnign of biology, but still hasn't moved forward too much - ANNs (neural networks) stil not plausible \n",
    "\n",
    "HTM theory - evolving, made significant progress, even simulating 1 layer of 1 regions - this gives alot already - aim to build out into stofotware\n",
    "\n",
    "TO find out more.....\n",
    "On intelligence\n",
    "numenta.com/learn \n",
    "\n",
    "\n",
    "\n",
    "VIDEO 2: \n",
    "BIt Arrays...... Episode 1\n",
    "\n",
    "precursor to SDR\n",
    "\n",
    "01101101 - 8 bit array - on or off, positive or negative- find capacity\n",
    "\n",
    "2^8 = 256, 8 elements number of bits 2^n is capacity of array, how many states it can have \n",
    "\n",
    "we can start on right, move over so \n",
    "1 x 1\n",
    "2 x 0\n",
    "4 x 1\n",
    "8 X 1 etc...\n",
    "\n",
    "so number above is 109....bit array has no semantic value\n",
    "\n",
    "ascii - character format in 8 bit format - 01101101 = \"m\" - arbitrary\n",
    "bits don't mean anything....so example of asci has no semantic value\n",
    "\n",
    "Basic binary operations....OR - if either is 1, is 1\n",
    "\n",
    "AND - simmilair, both must be positive, both be 1's, \n",
    "\n",
    "Also XOR variation.....only 1 or the  other can be 1, exclusive OR\n",
    "\n",
    "NOT - everyting just becoes NOT\n",
    "\n",
    "\"Population\" - how mahy positive values in a bit array\n",
    "00110011 = \"4\", also called \"Hamming Weight\", number of non-zero symbols\n",
    "\n",
    "Bigger bit array.....256 bits\n",
    "\n",
    "2 ^ 256 - 1 with 77 zeros after that - so lots of different states\n",
    "\n",
    "Sparsity vs density\n",
    "\n",
    "50%/50% - very dense\n",
    "\n",
    "vs 4/256 - very sparse.....also has much less capacity - 2% has fewer \n",
    "\n",
    "could store 4 onbits in array in 256 array in about 175million ways\n",
    "\n",
    "Sparse array as a way of representing features - 4 bits that are on could be \n",
    "bit 1 - is musiciian\n",
    "bit 2 - femae\n",
    "bit 3 - alive\n",
    "bit 4 - african american\n",
    "\n",
    "Would represent manynot all \n",
    "\n",
    "Compression \n",
    "if you have 50% propbabiliy of bieing on or off, can't compress\n",
    "\n",
    "for sparse array, we can compress - all we need to store indices on on bits \n",
    "\n",
    "4 x 8 bits gives for 8 bit numbers from 256 array, so storable in 32 bits\n",
    "\n",
    "So we can compress efficiently. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 193, 223, 47]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(range(0,256),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.0",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
