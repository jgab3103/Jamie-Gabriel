{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>STATUS: Draft<i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "from IPython.display import HTML, IFrame\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from matplotlib.patches import Rectangle\n",
    "from IPython.display import Image\n",
    "import sys\n",
    "import HTM_Code as hc\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last notebook, we built our first encoder. Admittedly, it was very simple. It just allows us to create integers and provide them to, and provide back indice location. It provided a little extra functionality so it could track previous, and comparison. And we established some rules that we would like to see in place. \n",
    "\n",
    "We also discussed what similiarity metrics in such an environment might look like, based on the rules. Its important to emphasie that we have really conflated the idea of semantic meaning, with distance, which is problematic, and we will need to take a deeper look at what it means to really encode something semantically. \n",
    "\n",
    "Finally, the Encoder Class that was introduced in the last notebook is also included in the HTM_Code.py file for us to use\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#99ddff; color:black; padding: 10px\">\n",
    "<b>Add to these notes:</b>\n",
    "\n",
    "I want to keep these notes in HTML so I don't have to host on a server, but a great exceriise is to use the ipython widgets to experience this like it happens in the video. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's double check everything still works, calling it now from our functions. We will create 3 different encoders, with differen types of features that we can now exploit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder:\n",
    "    def __init__(self, bit_space_size = None,\n",
    "                number_of_bits_used_to_encode_value = None,\n",
    "                min_val = None,\n",
    "                max_val = None,\n",
    "                is_randomly_distributed = None,\n",
    "                clip_values_outside_range = None):\n",
    "\n",
    "        self.bit_space_size = bit_space_size\n",
    "        self.number_of_bits_used_to_encode_value = number_of_bits_used_to_encode_value\n",
    "        self.clip_values_outside_range = clip_values_outside_range\n",
    "        self.is_periodic = False\n",
    "        self.is_randomly_distributed = is_randomly_distributed\n",
    "\n",
    "        self.resolution = 1\n",
    "        self.uniqueness = 1\n",
    "        self.min_value_to_encode = min_val\n",
    "        self.max_value_to_encode = max_val\n",
    "        self.max_bit_space_value = bit_space_size\n",
    "        self.min_bit_space_value = 0\n",
    "        self.encoded_values = []\n",
    "        self.encoded_values_bit_locations = []\n",
    "        self.offset_for_array_indice = 1\n",
    "        \n",
    "        self.bucket_capacity = self.compute_bucket_capacity(self.bit_space_size, self.number_of_bits_used_to_encode_value)\n",
    "        \n",
    "        if self.is_randomly_distributed:\n",
    "            self.initial_encoding = np.array(hc.create_randomised_sdr(self.bit_space_size, self.number_of_bits_used_to_encode_value))\n",
    "\n",
    "            self.encoded_values_and_bit_locations = {str(self.min_value_to_encode):self.initial_encoding}\n",
    "            self.encoded_values.append(self.min_value_to_encode)\n",
    "            self.encoded_values_bit_locations.append(np.array(self.initial_encoding))\n",
    "        \n",
    "    def get_summary(self):\n",
    "        print(\"----------------- SUMMARY -------------------------\")\n",
    "        print(\"|L3| Bit Space Size: \", self.bit_space_size)\n",
    "        print(\"|L4| Number of bits to be used when encoding each value:\", self.number_of_bits_used_to_encode_value)\n",
    "        print(\"|L5| Range of values that can be encoded: From \", self.min_value_to_encode, ' to ', self.max_value_to_encode)\n",
    "        print(\"|L6| Number of buckets available in bit space:\", float(self.bucket_capacity))\n",
    "        print(\"|L1| Encode periodically: \", self.is_periodic)\n",
    "        print(\"|L1| Values are encoded as are randomly distributed arrays: \", self.is_randomly_distributed)\n",
    "        print(\"|L1| Resolution: \", self.resolution)\n",
    "        print(\"|L1| Unique active bits per bucket: \", self.uniqueness)\n",
    "        print(\"|L2| Values outside range will to be clipped: \",self.clip_values_outside_range)\n",
    "        print(\"|L7| Encoded values bit locations:\\n \", self.encoded_values_bit_locations)\n",
    "        print(\"|L8| Encoded values\", self.encoded_values)\n",
    "        print(\"----------------------------------------------------\")\n",
    "\n",
    "        \n",
    "    def compute_bucket_capacity(self, n, w):\n",
    "        if self.is_randomly_distributed:\n",
    "            return(sp.binomial(self.bit_space_size, self.number_of_bits_used_to_encode_value))\n",
    "        else:\n",
    "            return(n - w + 1)\n",
    "\n",
    "    def create_buckets_for_randomly_encoded_values(self, iterations_needed):\n",
    "        \n",
    "        for i in range(0, iterations_needed):\n",
    "            random_bit_index_to_move = np.random.randint(0, self.number_of_bits_used_to_encode_value, 1)[0]\n",
    "            random_direction_to_move = np.random.randint(0, 2, 1)\n",
    "\n",
    "            next_sdr = self.encoded_values_bit_locations[-1].copy()\n",
    "            value = next_sdr[random_bit_index_to_move]\n",
    "            \n",
    "            if random_direction_to_move == 1:\n",
    "                value = next_sdr[random_bit_index_to_move] + 1\n",
    "            else: \n",
    "                value = next_sdr[random_bit_index_to_move] - 1\n",
    "                \n",
    "            if value > self.max_bit_space_value:\n",
    "                value = value - 2\n",
    "            elif value < 0:\n",
    "                value = value + 2\n",
    "\n",
    "            next_sdr[random_bit_index_to_move] = value\n",
    "\n",
    "            self.encoded_values_bit_locations.append(next_sdr.copy())\n",
    "            self.encoded_values.append(np.array(self.encoded_values[-1] + 1))\n",
    "            self.encoded_values_and_bit_locations[str(self.encoded_values[-1])] = next_sdr.copy()\n",
    "  \n",
    "\n",
    "    def encode_value_in_bit_space(self, value_choice):\n",
    "        print(\"\\nEncoding the value ->\", value_choice)\n",
    "        unclipped_value = value_choice\n",
    "        if self.clip_values_outside_range:\n",
    "            if value_choice < self.min_value_to_encode or value_choice > self.max_value_to_encode:\n",
    "                if value_choice < self.min_value_to_encode:\n",
    "                    value_choice = self.min_value_to_encode\n",
    "                else:\n",
    "                    value_choice = self.max_value_to_encode\n",
    "                print(\"The value of: \", unclipped_value, \"has been clipped to ->\", value_choice)\n",
    "            elif value_choice > self.min_value_to_encode or value_choice < self.max_value_to_encode:\n",
    "                pass\n",
    "        else:\n",
    "            print(\"Not a valid choice, \", value_choice, \" is outside encoder range\")\n",
    "            return\n",
    "\n",
    "        \n",
    "        if self.is_randomly_distributed:\n",
    "            if (value_choice < self.encoded_values[-1]):\n",
    "                print(\"There is a bucket already created for the value\", value_choice, \"-> \", self.encoded_values_and_bit_locations[str(value_choice)])\n",
    "                if unclipped_value < self.min_value_to_encode or unclipped_value > self.max_value_to_encode:\n",
    "                    print(\"This bucket will be used to encode\", unclipped_value)\n",
    "                    self.encoded_values_and_bit_locations[str(unclipped_value)] = self.encoded_values_and_bit_locations[str(value_choice)]\n",
    "                return\n",
    "            \n",
    "            buckets_needed_to_encode_value = value_choice - self.encoded_values[-1]\n",
    "            print(\"Current number of buckets: \" , len(self.encoded_values))\n",
    "            print(\"Value held in first bucket: \", self.min_value_to_encode)\n",
    "            print(\"Number of additional buckets required to accomodate the value choice of\", value_choice, \": \", buckets_needed_to_encode_value)\n",
    "            self.create_buckets_for_randomly_encoded_values(buckets_needed_to_encode_value)\n",
    "            self.encoded_values_and_bit_locations[str(unclipped_value)] = self.encoded_values_and_bit_locations[str(value_choice)]\n",
    "        \n",
    "        else:\n",
    "            window = [value_choice, value_choice + self.number_of_bits_used_to_encode_value]\n",
    "            all_values = np.arange(window[0], window[1])\n",
    "            self.encoded_values_bit_locations.append(all_values)\n",
    "            self.encoded_values.append(value_choice)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_space_size_choice = 64\n",
    "number_of_bits_used_to_encode_value_choice = 8\n",
    "\n",
    "e1 = Encoder(bit_space_size = bit_space_size_choice,\n",
    "                number_of_bits_used_to_encode_value = number_of_bits_used_to_encode_value_choice,\n",
    "                min_val = 0,\n",
    "                max_val = 1,\n",
    "            is_randomly_distributed = False,\n",
    "            clip_values_outside_range = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- SUMMARY -------------------------\n",
      "|L3| Bit Space Size:  64\n",
      "|L4| Number of bits to be used when encoding each value: 8\n",
      "|L5| Range of values that can be encoded: From  0  to  1\n",
      "|L6| Number of buckets available in bit space: 57.0\n",
      "|L1| Encode periodically:  False\n",
      "|L1| Values are encoded as are randomly distributed arrays:  False\n",
      "|L1| Resolution:  1\n",
      "|L1| Unique active bits per bucket:  1\n",
      "|L2| Values outside range will to be clipped:  False\n",
      "|L7| Encoded values bit locations:\n",
      "  []\n",
      "|L8| Encoded values []\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "e1.get_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>power_consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7/2/10 0:00</td>\n",
       "      <td>21.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7/2/10 1:00</td>\n",
       "      <td>16.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7/2/10 2:00</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7/2/10 3:00</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7/2/10 4:00</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     date_time  power_consumption\n",
       "1  7/2/10 0:00               21.2\n",
       "2  7/2/10 1:00               16.4\n",
       "3  7/2/10 2:00                4.7\n",
       "4  7/2/10 3:00                4.7\n",
       "5  7/2/10 4:00                4.6"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/gymdata.csv\", header=1)\n",
    "df = df.rename(columns={\"datetime\": \"date_time\", \"float\": \"power_consumption\"})\n",
    "df = df.iloc[1:]\n",
    "df.date_time = pd.to_datetime(df.date_time, format=\"%m/%d/%y %H:%M\")\n",
    "df['date'] = [d.date() for d in df.date_time]\n",
    "df['time_of_day'] = [d.time() for d in df.date_time]\n",
    "df['weekday'] = [d.weekday() for d in df.date]\n",
    "df['is_weekend'] = df.loc[df.weekday < 4, 'weekday'] = 0\n",
    "df['is_weekend'] = df.loc[df.weekday >= 4, 'weekday'] = 1\n",
    "df = df.drop('date_time', axis=1)\n",
    "#df = df.drop('weekday', axis=1)\n",
    "\n",
    "df.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now onto next episode of HTM School"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/PTYlge2K1G8\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f5a30419940>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"https://www.youtube.com/embed/PTYlge2K1G8\", width=600, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This episode is about how we might build Date and Time Encoder, but the way I like to think of this is . But the idea behind this is really that join multiple encoders togehter. For example, I might be interested in an encoder that takes 365 values, one for each day of the year, or just 2 values (one for whether it is weekend or not the weekend), 4 values (telling me which of the seasons of the year it is), or a minute encoder (telling which minute of the day). \n",
    "\n",
    "Under the hood, these are each no different from the encoders that we were already looking at. Each value that would stored is simply and SDR with active bits and an SDR size. \n",
    "\n",
    "I could join each of these encoders together (by simply concatentating the arrays), and I would in principle have an encoder that tracks the meaning of theach these, and I could feed into it a date and time, and see thier differen they are. \n",
    "\n",
    "To explore this further, let's build another class: a multi enncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiEncoder:\n",
    "    def __init__(self):\n",
    "        self.encoders = []\n",
    "        self.bit_space_size = None\n",
    "    def add_encoder(self, encoder):\n",
    "        self.encoders.append(encoder)\n",
    "    def join_encoders(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is a really powerful idea. We can think about multiple time series unfolding, date time components. Or we could think of symbolic music, track key changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_union_and_overlap(SDR1_on_bits, SDR2_on_bits):\n",
    "    union = list(set(SDR1_on_bits).union(SDR2_on_bits))\n",
    "    overlap = list(set(SDR1_on_bits).intersection(SDR2_on_bits))\n",
    "    \n",
    "    return({\"union\": union, \"overlap\": overlap})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is starting to seem more like we saw in the early notebooks, we can how semantic similairty is affected by noise and subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is alot more we can do with encoders. Delta encoder, log encoder. A geospatial encoder particularly interesting, enconding values on a sphere, what other geometrical shapes, opens us up to diffent types of geometry adn topology also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at more encoders: \n",
    "https://numenta.com/assets/pdf/biological-and-machine-intelligence/BaMI-Encoders.pdf\n",
    "\n",
    "IMportant to capture semantics properly\n",
    "\n",
    "4 principles recall..... eg consider two numbers should be semantically similiar \n",
    "\n",
    "Note for encoders, we can encode anything we can put in a relationship of \n",
    "\n",
    "we need encoders to have to to incorporate noise and subsamplinig \n",
    "\n",
    "Encoding Daa for HTM systems - Purdy\n",
    "\n",
    "\n",
    "Date Time Encoder\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
